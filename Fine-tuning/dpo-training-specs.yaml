model_args:
  base_model: "nicholasKluge/TeenyTinyLlama-460m"
  model_ref: "nicholasKluge/TeenyTinyLlama-460m"
  model_id: "460m"
  boi_token: "<instruction>"
  eoi_token: "</instruction>"
  cache_dir: null
  attn_implementation: "flash_attention_2"
data_args:
    dataset_name: "nicholasKluge/reward-aira-dataset"
    dataset_split: "portuguese"
    validation_split_percentage: 0.1
    max_prompt_length: 500
    max_length: 1500
    sanity_check: false
training_args:
  output_dir: "checkpoints"
  do_eval: true
  evaluation_strategy: "steps"
  save_strategy: "steps"
  logging_strategy: "steps"
  logging_steps: 500
  max_steps: 17500
  save_steps: 500
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 1
  gradient_checkpointing: true
  optim: "adamw_torch"
  learning_rate: 0.00001
  lr_scheduler_type: "cosine"
  warmup_steps: 1000
  hub_token: null
  push_to_hub: true
  hub_model_id: "nicholasKluge/TeenyTinyLlama-460m-Chat-DPO"
extra_args:
  logger_name: "TeenyTinyLlama"
  wandb_token: null
  beta: 0.7